{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daucco/.conda/envs/dev-gsicbr/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Project path is /home/daucco/ownCloud/unsync/_entregabledata/llms4mortality\n"
     ]
    }
   ],
   "source": [
    "## Project root path\n",
    "pjpath = ''\n",
    "\n",
    "# Hacky way of finding the project's root path. Do not rely on this, set your own pjpath!\n",
    "for p in Path.cwd().parents:\n",
    "    if p.stem == 'llms4mortality':\n",
    "        pjpath = p\n",
    "        break\n",
    "\n",
    "print(f'> Project path is {pjpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "# These must match the precomputed df\n",
    "samp_size = 5000\n",
    "balanced_data = True\n",
    "\n",
    "# This is only relevant if computing embedding from summaries (which need to be precomputed and available in disk)\n",
    "summaries = False       # If set, tries to load summaries from summary path and update text column in original data with them\n",
    "target_split = False    # Set this to the name of the split that you want to get the embeddings from. Otherwise set it to False to get emebeddings from the whole dataframe\n",
    "base_summ_model = 'll3' # Summarization ollama model. Only relevant if setting \"summaries\"\n",
    "max_chars = 22000       # Max chars used when generating summaries with ollama\n",
    "subsamp_size = False    # If set uses a subsample (over samp_size)\n",
    "\n",
    "# Model definition: Specify (model_name, batch_size, truncation_side)\n",
    "# brandonhcheung04/bart                         ## fine-tuned version of facebook/bart-base for abstractive summarization of clinical notes, trained on the MIMIC-IV dataset\n",
    "# Simonlee711/Clinical_ModernBERT               ## encoder-based transformer tailored specifically for biomedical and clinical text handling context length up to 8192 tokens\n",
    "# xyla/Clinical-T5                              ## T5 variants on the union of MIMIC-III and MIMIC-IV - NEED TO DOWNLOAD THE MODELS SEPARATELY!\n",
    "# all-distilroberta-v1                          ## Non-specific\n",
    "# medicalai/ClinicalBERT                        ## Healthcare-specific\n",
    "# emilyalsentzer/Bio_Discharge_Summary_BERT     ## MIMIC-III discharge notes\n",
    "# nazyrova/clinicalBERT                         ## MIIMC-IV discharge notes\n",
    "\n",
    "modnames = [\n",
    "    ## Big models:\n",
    "    #('Simonlee711/Clinical_ModernBERT', 4, 'left'),\n",
    "    #(f'{pjpath}/src/models/Clinical-T5-Scratch', 1, 'right')            # Too big for a commercial gpu\n",
    "    #('brandonhcheung04/bart', 32, 'left'),\n",
    "\n",
    "    ## Reasonable models\n",
    "    #('emilyalsentzer/Bio_Discharge_Summary_BERT', 256, 'right'),\n",
    "    #('all-distilroberta-v1', 256, 'right'),\n",
    "    #('medicalai/ClinicalBERT', 256, 'right'),\n",
    "    ('nazyrova/clinicalBERT', 256, 'right') # Found best\n",
    "]\n",
    "\n",
    "truncation_side = 'middle'  #   left, right, middle. Where to apply truncation when encoding. If middle, applies left & right and concatenates results (2 passes)\n",
    "prepend_columns = ['age', 'gender', 'insurance', 'marital_status', 'race', 'diagnose_group_description', 'diagnose_group_mortality']   # Columns in base dataframe to prepend to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to your MIMIC-IV path where discharge, patients and admissions tables are located\n",
    "mimicpath = pjpath / 'data/mimiciv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>text</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>insurance</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>race</th>\n",
       "      <th>diagnose_group_description</th>\n",
       "      <th>diagnose_group_mortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21891113</td>\n",
       "      <td>age: 68\\ngender: F\\ninsurance: Other\\nmarital ...</td>\n",
       "      <td>68</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>DISORDERS OF GALLBLADDER &amp; BILIARY TRACT, DISO...</td>\n",
       "      <td>MODERATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29643114</td>\n",
       "      <td>age: 96\\ngender: M\\ninsurance: Medicare\\nmarit...</td>\n",
       "      <td>96</td>\n",
       "      <td>M</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>CARDIAC ARRHYTHMIA &amp; CONDUCTION DISORDERS, ACU...</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26747385</td>\n",
       "      <td>age: 47\\ngender: F\\ninsurance: Other\\nmarital ...</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>ASIAN</td>\n",
       "      <td>DIGESTIVE MALIGNANCY, DIGESTIVE MALIGNANCY W MCC</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23932127</td>\n",
       "      <td>age: 64\\ngender: M\\ninsurance: Other\\nmarital ...</td>\n",
       "      <td>64</td>\n",
       "      <td>M</td>\n",
       "      <td>Other</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>PERCUTANEOUS CORONARY INTERVENTION W AMI, PERC...</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27210508</td>\n",
       "      <td>age: 72\\ngender: M\\ninsurance: Other\\nmarital ...</td>\n",
       "      <td>72</td>\n",
       "      <td>M</td>\n",
       "      <td>Other</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>INTRACRANIAL HEMORRHAGE, INTRACRANIAL HEMORRHA...</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id                                               text  age gender  \\\n",
       "0  21891113  age: 68\\ngender: F\\ninsurance: Other\\nmarital ...   68      F   \n",
       "1  29643114  age: 96\\ngender: M\\ninsurance: Medicare\\nmarit...   96      M   \n",
       "2  26747385  age: 47\\ngender: F\\ninsurance: Other\\nmarital ...   47      F   \n",
       "3  23932127  age: 64\\ngender: M\\ninsurance: Other\\nmarital ...   64      M   \n",
       "4  27210508  age: 72\\ngender: M\\ninsurance: Other\\nmarital ...   72      M   \n",
       "\n",
       "  insurance marital_status   race  \\\n",
       "0     Other       DIVORCED  WHITE   \n",
       "1  Medicare        WIDOWED  WHITE   \n",
       "2     Other        MARRIED  ASIAN   \n",
       "3     Other        MARRIED  WHITE   \n",
       "4     Other        MARRIED  WHITE   \n",
       "\n",
       "                          diagnose_group_description diagnose_group_mortality  \n",
       "0  DISORDERS OF GALLBLADDER & BILIARY TRACT, DISO...                 MODERATE  \n",
       "1  CARDIAC ARRHYTHMIA & CONDUCTION DISORDERS, ACU...                     HIGH  \n",
       "2   DIGESTIVE MALIGNANCY, DIGESTIVE MALIGNANCY W MCC                     HIGH  \n",
       "3  PERCUTANEOUS CORONARY INTERVENTION W AMI, PERC...                      LOW  \n",
       "4  INTRACRANIAL HEMORRHAGE, INTRACRANIAL HEMORRHA...                     HIGH  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load precomputed dataframe. Keeps only hadm_id and text\n",
    "df = pd.read_csv(mimicpath / f'mimiciv_4_mortality_S{samp_size}{'_balanced' if balanced_data else ''}.csv.gz')[['hadm_id', 'text', *prepend_columns]]\n",
    "\n",
    "# Expected summary name\n",
    "summary_id = f'summary_S{str(samp_size)}{'_balanced' if balanced_data else ''}{'_sp' + target_split if target_split else ''}_{base_summ_model}_mc{str(max_chars)}{'_ss' + str(subsamp_size) if subsamp_size else ''}'\n",
    "\n",
    "if summaries:\n",
    "    print(f'> (!) Using summaries')\n",
    "    # Use precomputed summaries instead of text. Load them from disk\n",
    "    df_summ = pd.read_csv(mimicpath / f'summaries/{summary_id}.csv', index_col=0)\n",
    "    df_summ.index.rename('hadm_id', inplace=True)\n",
    "    df = pd.merge(df, df_summ, on='hadm_id', how='inner')\n",
    "    df['text'] = df.apply(lambda x: x['SUMMARY'], axis=1)\n",
    "\n",
    "# Preprends patient data to text column. Replaces underscore with spaces in both, feature name and value\n",
    "df['text'] = df.apply(lambda x: ''.join([f'{p_cname.replace('_', ' ')}: {str(x[p_cname]).replace('_', ' ')}\\n' for p_cname in prepend_columns]) + x['text'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getes sentence embeddings for each model\n",
    "encoder_kwargs = {\n",
    "    #'batch_size': encoding_bsize,\n",
    "    'output_value': 'sentence_embedding',\n",
    "    'show_progress_bar': True,\n",
    "    'convert_to_numpy': True\n",
    "}\n",
    "\n",
    "m_count = 1\n",
    "for modname, mod_bsize, mod_truncation in modnames:\n",
    "    print(f'> Processing model {m_count}/{len(modnames)} - ({modname})')\n",
    "    if mod_truncation == 'middle':\n",
    "        # Truncates right, gets left-side embeddings\n",
    "        model = SentenceTransformer(modname, tokenizer_kwargs={'truncation_side': 'right'})\n",
    "        embeddings_l = model.encode(df.text.to_list(), batch_size=mod_bsize, **encoder_kwargs)\n",
    "\n",
    "        # Truncates right, gets left-side embeddings\n",
    "        model = SentenceTransformer(modname, tokenizer_kwargs={'truncation_side': 'left'})\n",
    "        embeddings_r = model.encode(df.text.to_list(), batch_size=mod_bsize, **encoder_kwargs)\n",
    "\n",
    "        # Concatenates tensors horizontally\n",
    "        embeddings = np.concatenate((embeddings_l, embeddings_r), axis=1)\n",
    "\n",
    "    else:\n",
    "        model = SentenceTransformer(modname, tokenizer_kwargs={'truncation_side': mod_truncation})\n",
    "        embeddings = model.encode(df.text.to_list(), batch_size=mod_bsize, **encoder_kwargs)\n",
    "\n",
    "    # Exports result to disk\n",
    "    print(f'> Exporting resulting embeddings to {mimicpath}...')\n",
    "    with open(mimicpath / f'embeddings_{re.sub('[^a-zA-Z0-9]+', '', modname)}_{'summary_' if summaries else ''}S{samp_size}_T{mod_truncation}{'_balanced' if balanced_data else ''}{'_PR' if len(prepend_columns)>0 else ''}.npy', 'wb') as ofile:\n",
    "        np.save(ofile, embeddings)\n",
    "\n",
    "    m_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-gsicbr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Sample data\n",
    "samp_size = 5000\n",
    "\n",
    "# Create 4-splits (train, test, validation and case base for cbr)\n",
    "split_ratios = {\n",
    "    'cb': .4,\n",
    "    'train': .3,\n",
    "    'test': .2,\n",
    "    'val': .1       \n",
    "}\n",
    "\n",
    "# Set to true if forcing case balance per mortality\n",
    "balanced_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Project path is /home/daucco/ownCloud-UPM/CBR/llms4mortality\n"
     ]
    }
   ],
   "source": [
    "## Project root path\n",
    "pjpath = ''\n",
    "\n",
    "# Hacky way of finding the project's root path. Do not rely on this, set your own pjpath!\n",
    "for p in Path.cwd().parents:\n",
    "    if p.stem == 'llms4mortality':\n",
    "        pjpath = p\n",
    "        break\n",
    "\n",
    "print(f'> Project path is {pjpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to your MIMIC-IV path where discharge, patients and admissions tables are located\n",
    "mimicpath = pjpath / 'data/mimiciv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading tables...\n",
      "> Fixing date types...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8257/1364889006.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_drgs_mortality['drg_mortality'] = df_drgs_mortality['drg_mortality'].apply(lambda x: x if x in list(mortality_rank2literal.keys()) else -1)\n"
     ]
    }
   ],
   "source": [
    "# Load data from discharge, patients and admissions tables. Keep only relevant columns\n",
    "print('> Loading tables...')\n",
    "df_discharge = pd.read_csv(mimicpath / 'discharge.csv.gz')[['note_id', 'subject_id', 'hadm_id', 'charttime', 'text']]\n",
    "df_patients = pd.read_csv(mimicpath / 'patients.csv.gz')[['subject_id', 'gender', 'dod', 'anchor_age', 'anchor_year']]\n",
    "df_admissions = pd.read_csv(mimicpath / 'admissions.csv.gz')[['hadm_id', 'admittime', 'admission_type', 'insurance', 'marital_status', 'race']]\n",
    "df_drgs = pd.read_csv(mimicpath / 'drgcodes.csv.gz')[['hadm_id', 'description', 'drg_mortality', 'drg_code']]\n",
    "\n",
    "# Fixes date columns across tables\n",
    "print('> Fixing date types...')\n",
    "df_discharge['charttime'] = pd.to_datetime(df_discharge['charttime'], format='%Y-%m-%d %H:%M:%S').dt.date\n",
    "df_patients['dod'] = pd.to_datetime(df_patients['dod'], format='%Y-%m-%d').dt.date\n",
    "df_admissions['admittime'] = pd.to_datetime(df_admissions['admittime'].apply(lambda x: x.split(' ')[0]), format='%Y-%m-%d').dt.date # We are only interested in y-m-d\n",
    "\n",
    "# Fix drg codes\n",
    "\n",
    "## Descriptions\n",
    "# Concatenates multiple drg descriptions for the same hadm_id\n",
    "df_drgs_descs = df_drgs[['hadm_id', 'description']].groupby('hadm_id')['description'].apply(lambda x: ', '.join(x)).to_frame(name='diagnose_group_description')\n",
    "\n",
    "## Moratility risk rank\n",
    "df_drgs_mortality = df_drgs[['hadm_id', 'drg_mortality']]\n",
    "# Helper dic to transform drg_mortality rank into literals\n",
    "mortality_rank2literal = {\n",
    "    1: 'LOW',\n",
    "    2: 'MODERATE',\n",
    "    3: 'HIGH',\n",
    "    4: 'VERY HIGH'\n",
    "}\n",
    "\n",
    "# Finds invalid ranks\n",
    "df_drgs_mortality['drg_mortality'] = df_drgs_mortality['drg_mortality'].apply(lambda x: x if x in list(mortality_rank2literal.keys()) else -1)\n",
    "mortality_rank2literal[-1] = 'UNKOWN'   # Literal for unkown ranks\n",
    "\n",
    "# Keeps only highest mortality rank per hadm_id\n",
    "df_drgs_mortality = df_drgs_mortality.groupby('hadm_id')['drg_mortality'].max().to_frame(name='drg_mortality')\n",
    "\n",
    "# Gets literals\n",
    "df_drgs_mortality['diagnose_group_mortality'] = df_drgs_mortality['drg_mortality'].apply(lambda x: mortality_rank2literal[x])\n",
    "\n",
    "# Combines descriptions and processed rank into single frame\n",
    "df_drgs_m = pd.merge(df_drgs_descs, df_drgs_mortality, 'inner', on='hadm_id')\n",
    "\n",
    "# Combines all drg codes into a single column (as a list of codes).\n",
    "df_drgs_code = df_drgs[['hadm_id', 'drg_code']].groupby('hadm_id').agg(list)\n",
    "\n",
    "# Merges into single frame\n",
    "df_drgs = pd.merge(df_drgs_m, df_drgs_code, 'inner', on='hadm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging...\n",
      "> Resolving additional columns...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8257/4213372719.py:20: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['delta_days_dod'].loc[hadm_ids_dead] = df.loc[hadm_ids_dead].apply(lambda e: int((e['dod'] - e['charttime']).days), axis=1)\n",
      "/tmp/ipykernel_8257/4213372719.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['delta_days_dod'].loc[hadm_ids_dead] = df.loc[hadm_ids_dead].apply(lambda e: int((e['dod'] - e['charttime']).days), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Balancing data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Main df generation\n",
    "\n",
    "# Merge tables and fix index to hadm_id (unique in generated merge)\n",
    "print('> Merging...')\n",
    "df = pd.merge(df_discharge, df_patients, on='subject_id', how='inner')\n",
    "df = pd.merge(df, df_admissions, on='hadm_id', how='inner')\n",
    "df = pd.merge(df, df_drgs, on='hadm_id', how='inner')\n",
    "df.set_index('hadm_id', inplace=True)\n",
    "\n",
    "print('> Resolving additional columns...')\n",
    "# Resolves age of patient at (each) hospital admission\n",
    "df['age'] = df['charttime'].apply(lambda x: x.year) - df['anchor_year'] + df['anchor_age']\n",
    "\n",
    "# 1. Finds hadm_id of cases for which there's a dod registered\n",
    "#   Assumes that if there's no dod, then dod==NaN!=NaN\n",
    "hadm_ids_dead = df[df['dod'] == df['dod']].index\n",
    "\n",
    "# 2. Resolves delta_days_dod: days passed from any given report to patient death where applicable. -1 if no registry of patient death\n",
    "df['delta_days_dod'] = -1\n",
    "df['delta_days_dod'].loc[hadm_ids_dead] = df.loc[hadm_ids_dead].apply(lambda e: int((e['dod'] - e['charttime']).days), axis=1)\n",
    "#df['delta_days_dod'].loc[predeath_note_idx] = df.loc[predeath_note_idx].apply(lambda e: int((e['dod'] - e['charttime']).days), axis=1)\n",
    "\n",
    "## 3. Drop instances where delta_days_dod == 0. (patient died on arrival (DOA) or shortly after (~same day))\n",
    "#   In most of these, there's direct mention to the patient's death in the report, hence these are invalid for the mortality prediction task\n",
    "df = df[~(df['delta_days_dod'] == 0)]\n",
    "\n",
    "## 5. Balance data if specified\n",
    "if balanced_data:\n",
    "    \"\"\"\n",
    "        To create a balanced set we consider 3 types of patient profiles depending on when they died according to the mimic registry\n",
    "            1. Never or later than 365 days after discharge (delta_days_dod == -1 or delta_days_dod > 365)\n",
    "            2. Within 30 days after discharge (0 < delta_days_dod <= 30)\n",
    "            3. Within 30 and 365 days after discharge (30 < delta_days_dod <= 365)\n",
    "        This ensures a uniform proportion of discharge notes in terms of the type of mortality they encompass\n",
    "    \"\"\"\n",
    "    print(f'> Balancing data...')\n",
    "\n",
    "    # Find the total number of instances of each considered type:\n",
    "    df_died_after_365 = df[df['delta_days_dod'].apply(lambda x: x == -1 or x > 365)]\n",
    "    df_died_within_30 = df[df['delta_days_dod'].apply(lambda x: x > 0 and x <= 30)]\n",
    "    df_died_within_30365 = df[df['delta_days_dod'].apply(lambda x: x > 30 and x <= 365)]\n",
    "\n",
    "    n_total = len(df)\n",
    "\n",
    "    n_died_after_365 = len(df_died_after_365)\n",
    "    n_died_within_30 = len(df_died_within_30)\n",
    "    n_died_within_30365 = len(df_died_within_30365)\n",
    "\n",
    "    # Resolves the number of samples of the smaller subset, then samples the rest to this number\n",
    "    n_smaller = min(n_died_after_365, n_died_within_30, n_died_within_30365)\n",
    "    df_died_after_365 = df_died_after_365.sample(n=n_smaller, random_state=SEED)\n",
    "    df_died_within_30 = df_died_within_30.sample(n=n_smaller, random_state=SEED)\n",
    "    df_died_within_30365 = df_died_within_30365.sample(n=n_smaller, random_state=SEED)\n",
    "\n",
    "    # Updates df with balanced samples\n",
    "    df = pd.concat((df_died_after_365, df_died_within_30, df_died_within_30365))\n",
    "\n",
    "    # Updates samp_size if not enough samples in new balanced set\n",
    "    samp_size = min(samp_size, 3*n_smaller)\n",
    "\n",
    "# Fix unkown drg_mortality\n",
    "df['drg_mortality'] = df['drg_mortality'].fillna(-1)\n",
    "\n",
    "# Fix missing values on non-essential columns that can have nans (except dod, it might be useful to have an actual nan here)\n",
    "df.loc[:, df.columns != 'dod'] = df.loc[:, df.columns != 'dod'].fillna('UNKOWN')\n",
    "\n",
    "# Resets index\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Fix numerical types\n",
    "numeric_columns = ['age', 'drg_mortality']\n",
    "df = df.astype({cname: int for cname in numeric_columns})\n",
    "\n",
    "# Take a sample\n",
    "df_samp = df.sample(samp_size, random_state=SEED)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also get dummies from categorical data. This will later be useful to assess similarity out of these values\n",
    "categorical_columns = ['gender', 'admission_type', 'insurance', 'marital_status', 'race']\n",
    "\n",
    "df_dummies = df_samp.copy()\n",
    "for category in categorical_columns:\n",
    "    df_dummies = pd.get_dummies(df_dummies, prefix=category, prefix_sep='_', columns=[category])\n",
    "\n",
    "# Special treatment for drg_codes\n",
    "# First we evaluate data, as it was reimported as strings instead of lists\n",
    "df_drg = df_dummies.set_index('hadm_id')['drg_code'].to_frame()\n",
    "\n",
    "# Then we explode values\n",
    "df_drg = df_drg.explode('drg_code')\n",
    "\n",
    "# Aggregate categoricals into a single row per hadm_id (index)\n",
    "df_drg = pd.get_dummies(df_drg, prefix='drg_code', prefix_sep='_', columns=['drg_code']).groupby('hadm_id').sum()\n",
    "\n",
    "# Drop original drg_code from df and merge with drg_code\n",
    "df_dummies = df_dummies.drop(columns=['drg_code'])\n",
    "df_dummies = pd.merge(df_dummies, df_drg, on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25959, 20)\n",
      "Index(['hadm_id', 'note_id', 'subject_id', 'charttime', 'text', 'gender',\n",
      "       'dod', 'anchor_age', 'anchor_year', 'admittime', 'admission_type',\n",
      "       'insurance', 'marital_status', 'race', 'diagnose_group_description',\n",
      "       'drg_mortality', 'diagnose_group_mortality', 'drg_code', 'age',\n",
      "       'delta_days_dod'],\n",
      "      dtype='object')\n",
      "(5000, 727)\n",
      "Index(['hadm_id', 'note_id', 'subject_id', 'charttime', 'text', 'dod',\n",
      "       'anchor_age', 'anchor_year', 'admittime', 'diagnose_group_description',\n",
      "       ...\n",
      "       'drg_code_974', 'drg_code_975', 'drg_code_976', 'drg_code_977',\n",
      "       'drg_code_981', 'drg_code_982', 'drg_code_983', 'drg_code_987',\n",
      "       'drg_code_988', 'drg_code_989'],\n",
      "      dtype='object', length=727)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>note_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>dod</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>anchor_year</th>\n",
       "      <th>admittime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>insurance</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>race</th>\n",
       "      <th>diagnose_group_description</th>\n",
       "      <th>drg_mortality</th>\n",
       "      <th>diagnose_group_mortality</th>\n",
       "      <th>drg_code</th>\n",
       "      <th>age</th>\n",
       "      <th>delta_days_dod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23149593</td>\n",
       "      <td>15076868-DS-14</td>\n",
       "      <td>15076868</td>\n",
       "      <td>2125-06-15</td>\n",
       "      <td>\\nName:  ___               Unit No:   ___\\n \\...</td>\n",
       "      <td>F</td>\n",
       "      <td>NaT</td>\n",
       "      <td>77</td>\n",
       "      <td>2125</td>\n",
       "      <td>2125-06-08</td>\n",
       "      <td>OBSERVATION ADMIT</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>DORSAL &amp; LUMBAR FUSION PROC EXCEPT FOR CURVATU...</td>\n",
       "      <td>1</td>\n",
       "      <td>LOW</td>\n",
       "      <td>[304, 454]</td>\n",
       "      <td>77</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25964724</td>\n",
       "      <td>18335259-DS-3</td>\n",
       "      <td>18335259</td>\n",
       "      <td>2176-03-22</td>\n",
       "      <td>\\nName:  ___                  Unit No:   ___\\...</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>56</td>\n",
       "      <td>2172</td>\n",
       "      <td>2176-03-20</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>Other</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>DISORDERS OF PANCREAS EXCEPT MALIGNANCY, DISOR...</td>\n",
       "      <td>1</td>\n",
       "      <td>LOW</td>\n",
       "      <td>[282, 440]</td>\n",
       "      <td>60</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25340693</td>\n",
       "      <td>18410637-DS-21</td>\n",
       "      <td>18410637</td>\n",
       "      <td>2122-10-26</td>\n",
       "      <td>\\nName:  ___                Unit No:   ___\\n ...</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>69</td>\n",
       "      <td>2122</td>\n",
       "      <td>2122-10-07</td>\n",
       "      <td>OBSERVATION ADMIT</td>\n",
       "      <td>Other</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE - RUSSIAN</td>\n",
       "      <td>RADIOTHERAPY, PERIPH/CRANIAL NERVE &amp; OTHER NER...</td>\n",
       "      <td>4</td>\n",
       "      <td>VERY HIGH</td>\n",
       "      <td>[692, 40]</td>\n",
       "      <td>69</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20291958</td>\n",
       "      <td>16328062-DS-16</td>\n",
       "      <td>16328062</td>\n",
       "      <td>2176-04-14</td>\n",
       "      <td>\\nName:  ___                 Unit No:   ___\\n...</td>\n",
       "      <td>F</td>\n",
       "      <td>NaT</td>\n",
       "      <td>79</td>\n",
       "      <td>2176</td>\n",
       "      <td>2176-04-11</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>OTHER COMPLICATIONS OF TREATMENT, COMPLICATION...</td>\n",
       "      <td>1</td>\n",
       "      <td>LOW</td>\n",
       "      <td>[813, 921]</td>\n",
       "      <td>79</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21828253</td>\n",
       "      <td>14387168-DS-9</td>\n",
       "      <td>14387168</td>\n",
       "      <td>2159-03-16</td>\n",
       "      <td>\\nName:  ___               Unit No:   ___\\n \\...</td>\n",
       "      <td>F</td>\n",
       "      <td>NaT</td>\n",
       "      <td>37</td>\n",
       "      <td>2159</td>\n",
       "      <td>2159-03-07</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>UNKOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BIPOLAR DISORDERS, PSYCHOSES</td>\n",
       "      <td>1</td>\n",
       "      <td>LOW</td>\n",
       "      <td>[753, 885]</td>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id         note_id  subject_id   charttime  \\\n",
       "0  23149593  15076868-DS-14    15076868  2125-06-15   \n",
       "1  25964724   18335259-DS-3    18335259  2176-03-22   \n",
       "2  25340693  18410637-DS-21    18410637  2122-10-26   \n",
       "3  20291958  16328062-DS-16    16328062  2176-04-14   \n",
       "4  21828253   14387168-DS-9    14387168  2159-03-16   \n",
       "\n",
       "                                                text gender  dod  anchor_age  \\\n",
       "0   \\nName:  ___               Unit No:   ___\\n \\...      F  NaT          77   \n",
       "1   \\nName:  ___                  Unit No:   ___\\...      M  NaT          56   \n",
       "2   \\nName:  ___                Unit No:   ___\\n ...      M  NaT          69   \n",
       "3   \\nName:  ___                 Unit No:   ___\\n...      F  NaT          79   \n",
       "4   \\nName:  ___               Unit No:   ___\\n \\...      F  NaT          37   \n",
       "\n",
       "   anchor_year   admittime     admission_type insurance marital_status  \\\n",
       "0         2125  2125-06-08  OBSERVATION ADMIT  Medicare        WIDOWED   \n",
       "1         2172  2176-03-20           EW EMER.     Other        MARRIED   \n",
       "2         2122  2122-10-07  OBSERVATION ADMIT     Other        MARRIED   \n",
       "3         2176  2176-04-11           EW EMER.  Medicare         SINGLE   \n",
       "4         2159  2159-03-07             URGENT  Medicare         UNKOWN   \n",
       "\n",
       "              race                         diagnose_group_description  \\\n",
       "0            WHITE  DORSAL & LUMBAR FUSION PROC EXCEPT FOR CURVATU...   \n",
       "1            WHITE  DISORDERS OF PANCREAS EXCEPT MALIGNANCY, DISOR...   \n",
       "2  WHITE - RUSSIAN  RADIOTHERAPY, PERIPH/CRANIAL NERVE & OTHER NER...   \n",
       "3            WHITE  OTHER COMPLICATIONS OF TREATMENT, COMPLICATION...   \n",
       "4          UNKNOWN                       BIPOLAR DISORDERS, PSYCHOSES   \n",
       "\n",
       "   drg_mortality diagnose_group_mortality    drg_code  age  delta_days_dod  \n",
       "0              1                      LOW  [304, 454]   77              -1  \n",
       "1              1                      LOW  [282, 440]   60              -1  \n",
       "2              4                VERY HIGH   [692, 40]   69              -1  \n",
       "3              1                      LOW  [813, 921]   79              -1  \n",
       "4              1                      LOW  [753, 885]   37              -1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df_dummies.shape)\n",
    "print(df_dummies.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and export\n",
    "\n",
    "df_id = f'mimiciv_4_mortality_S{samp_size}{'_balanced' if balanced_data else ''}'\n",
    "\n",
    "# Split by subject to avoid leakage\n",
    "subj_cb_train, subj_test_val = train_test_split(df_samp['subject_id'].unique(), train_size=(split_ratios['cb'] + split_ratios['train']), random_state=SEED)\n",
    "\n",
    "# Second level split (accounts for it in train_size)\n",
    "subj_cb, subj_train, = train_test_split(subj_cb_train, train_size=(split_ratios['cb'] / (split_ratios['cb']+split_ratios['train'])), random_state=SEED)\n",
    "subj_test, subj_val, = train_test_split(subj_test_val, train_size=(split_ratios['test'] / (split_ratios['test']+split_ratios['val'])), random_state=SEED)\n",
    "\n",
    "# Resolves hadm_id from subject_id for each split. These will be the unique indices used later to resolve the entries of each split in the main df\n",
    "splits_hadmids = {}\n",
    "for sname, ssubj_idx in zip(('cb', 'train', 'test', 'val'), (subj_cb, subj_train, subj_test, subj_val)):\n",
    "    splits_hadmids[sname] = df_samp[df_samp['subject_id'].isin(ssubj_idx)]['hadm_id'].to_list()\n",
    "\n",
    "# Export full sampled dataframes and split info to disk\n",
    "df_samp.to_csv(mimicpath / f'{df_id}.csv.gz', index=False)\n",
    "df_dummies.to_csv(mimicpath / f'd_{df_id}.csv.gz', index=False)\n",
    "\n",
    "with open(mimicpath / f'hadmid_splits_S{samp_size}{'_balanced' if balanced_data else ''}.json', 'w') as ofile:\n",
    "    json.dump(splits_hadmids, ofile)\n",
    "\n",
    "# Also exports sorted list of hadm_ids for the sample as a separate json file\n",
    "with open(mimicpath / f'hadmid_sorted_S{samp_size}{'_balanced' if balanced_data else ''}.json', 'w') as ofile:\n",
    "    json.dump({'HADM_ID': df_samp['hadm_id'].to_list()}, ofile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoT mortality prediction using precomputed summaries from both, test entries and examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from src.minicbr import MiniCBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Project path is /home/daucco/ownCloud-UPM/CBR/llms4mortality\n"
     ]
    }
   ],
   "source": [
    "## Project root path\n",
    "pjpath = ''\n",
    "\n",
    "# Hacky way of finding the project's root path. Do not rely on this, set your own pjpath!\n",
    "for p in Path.cwd().parents:\n",
    "    if p.stem == 'llms4mortality':\n",
    "        pjpath = p\n",
    "        break\n",
    "\n",
    "print(f'> Project path is {pjpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant paths\n",
    "mimicpath = pjpath / 'data/mimiciv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "## Controls which data file to load\n",
    "samp_size = 5000\n",
    "balanced_data = True\n",
    "max_chars = 22000       # Anything longer than this will be middle-truncated\n",
    "\n",
    "## CBR configs\n",
    "#knn = 1\n",
    "weighted = True\n",
    "summary_mode = False    # Whether to use summaries in the CBR part of the query (ie, finding neighbours)\n",
    "withprepended = True    # Whether to load embeddings that were computed out of texts with preprended patient info\n",
    "# Load by name and truncation side\n",
    "modname, mod_truncation = ('nazyrova/clinicalBERT', 'middle')\n",
    "# Default feature map for dynamic weighted\n",
    "feature_map = {\n",
    "    'emb': ('cosine', False, 0.33),\n",
    "    'age': ('euclidean', True, 0.33),\n",
    "    #'gender': ('jaccard', False, .07),\n",
    "    #'admission_type': ('jaccard', False, .07),\n",
    "    #'insurance': ('jaccard', False, .07),\n",
    "    #'marital_status': ('jaccard', False, .07),\n",
    "    #'race': ('jaccard', False, .07),\n",
    "    'drg_mortality': ('euclidean', True, 0.33),\n",
    "    #'drg_code': ('jaccard', False, .07),\n",
    "}\n",
    "\n",
    "## Controls which LLM model to fire\n",
    "base_models = [\n",
    "    'llama3',\n",
    "    #'medgenius32b',\n",
    "    #'dsmedical8b',\n",
    "    #'biomistral7b'\n",
    "]\n",
    "\n",
    "## Paths to your system prompt json files\n",
    "# These should contain dictionaries where keys are short ids for each prompt type, and the values is another dictionary with at least \"prompt\"\n",
    "sysprompt_in_fpath = pjpath / 'ollama/sysprompts/sysprompt_in.json'\n",
    "sysprompt_out_fpath = pjpath / 'ollama/sysprompts/sysprompt_out.json'   # Should also contain \"format\" key with the expected output format\n",
    "\n",
    "# Type of input and output system prompts. Define only a single value for each.\n",
    "i_type_id = 'S'\n",
    "o_type_id = 'M'\n",
    "\n",
    "## LLM params\n",
    "n_ctx = 32      # Context length (x 1024)\n",
    "temp = 0.1      #[0.0, *0.1, 0.3, 0.7, 1.0]   # Temperature option for the LLM. The greater, the more creative the answer (def 0.1)\n",
    "top_k = 20\n",
    "top_p = 0.5\n",
    "ss_size = 200\n",
    "\n",
    "## Additional data prepro options\n",
    "# This is the collection of columns that contains the relevant patient info that will be provided to the LLM with the text report\n",
    "# Remapping some column names to make them more significant in the prompt\n",
    "pdc_remap = {\n",
    "    'age': 'AGE',\n",
    "    'gender': 'GENDER',\n",
    "    'marital_status': 'MARITAL STATUS',\n",
    "    'race': 'RACE',\n",
    "    'diagnose_group_description': 'BROAD DIAGNOSIS',\n",
    "    'diagnose_group_mortality': 'MORTALITY RISK',\n",
    "    'insurance': 'INSURANCE',\n",
    "    #'text': 'REPORT'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Load precomputed dataframe.\n",
    "dfname = f'mimiciv_4_mortality_S{samp_size}{'_balanced' if balanced_data else ''}'\n",
    "df = pd.read_csv(mimicpath / f'{dfname}.csv.gz')\n",
    "\n",
    "# We also need the dummies for CBR\n",
    "df_dummies = pd.read_csv(mimicpath / f'd_{dfname}.csv.gz')\n",
    "\n",
    "# Resolve target (ie, mortality within 30 days of discharge)\n",
    "df['DIES'] = df['delta_days_dod'].apply(lambda x: x > 0 and x <= 30)\n",
    "df_dummies['DIES'] = df_dummies['delta_days_dod'].apply(lambda x: x > 0 and x <= 30)\n",
    "\n",
    "# Load precomputed splits\n",
    "with open(mimicpath / f'hadmid_splits_S{samp_size}{'_balanced' if balanced_data else ''}.json', 'r') as ifile:\n",
    "    splits_hadmids = json.load(ifile)\n",
    "    \n",
    "# Load sorted hadm_ids from disk\n",
    "with open(mimicpath / f'hadmid_sorted_S{samp_size}{'_balanced' if balanced_data else ''}.json', 'r') as ifile:\n",
    "    emb_hadmids = json.load(ifile)['HADM_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve test data\n",
    "\n",
    "df_test = df.set_index('hadm_id').loc[splits_hadmids['test']]\n",
    "df = df.set_index('hadm_id')\n",
    "df['DIES'] = df['DIES'].apply(lambda x: 'YES' if x else 'NO')   # Need to do this for json\n",
    "df_test = df_test.sample(ss_size, random_state=SEED) if ss_size else df_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading embeddings from embeddings_nazyrovaclinicalBERT_S5000_Tmiddle_balanced_PR.npy...\n",
      "> Finding neighbours for test entries...\n"
     ]
    }
   ],
   "source": [
    "# Loads embeddings\n",
    "\n",
    "# Path where embeddings are located\n",
    "embpath = mimicpath / 'embeddings'\n",
    "\n",
    "modname = re.sub('[^a-zA-Z0-9]+', '', modname)\n",
    "mod_fname = f'embeddings_{modname}_{'summary_' if summary_mode else ''}S{samp_size}_T{mod_truncation}{'_balanced' if balanced_data else ''}{'_PR' if withprepended else ''}.npy'\n",
    "print(f'> Loading embeddings from {mod_fname}...')\n",
    "embeddings = np.load(embpath / mod_fname)\n",
    "\n",
    "# hadmid-index mappings (and back)\n",
    "hadm2idx = {hadm: i for i, hadm in enumerate(emb_hadmids)}\n",
    "idx2hadm = {i: hadm for hadm, i in hadm2idx.items()}\n",
    "\n",
    "# Put embeddings in df iteratively taking their hadm_id into account\n",
    "df_embs = pd.DataFrame(columns=['emb'])\n",
    "df_embs.index.name = 'hadm_id'\n",
    "for i, emb in enumerate(embeddings):\n",
    "    #df_embs.at[len(df_embs), 'emb'] = emb\n",
    "    df_embs.at[idx2hadm[i], 'emb'] = emb\n",
    "\n",
    "# Merge df_embs with actual data df\n",
    "_df = df_dummies.copy()\n",
    "_df = pd.merge(_df, df_embs, on='hadm_id', how='inner')\n",
    "\n",
    "# Columns to keep in main dataframe for the experiment\n",
    "target_prefixes = ['age', 'gender', 'admission_type', 'insurance', 'marital_status', 'race', 'drg_mortality', 'drg_code', 'emb']\n",
    "sol_prefixes = ['DIES']\n",
    "\n",
    "target_columns = [c for c in _df.columns if c.startswith(tuple(target_prefixes))]\n",
    "\n",
    "# Prepares data for CBR model\n",
    "dfd_cb_X = _df.set_index('hadm_id').loc[splits_hadmids['cb']][target_columns]\n",
    "dfd_test_X = _df.set_index('hadm_id').loc[df_test.index][target_columns]\n",
    "\n",
    "dfd_cb_y = _df.set_index('hadm_id').loc[splits_hadmids['cb']][sol_prefixes]\n",
    "dfd_test_y = _df.set_index('hadm_id').loc[df_test.index][sol_prefixes]\n",
    "\n",
    "# Initializes MiniCBR and resolves 1NN neighbours for test data\n",
    "print(f'> Finding neighbours for test entries...')\n",
    "mcbr = MiniCBR(df_X=dfd_cb_X, df_y=dfd_cb_y, feature_map=feature_map)\n",
    "ndists, nidxs = mcbr.find(dfd_test_X, 1)\n",
    "\n",
    "# Translate natural indices into actual hadm_id from neighbours. Save as a separate df\n",
    "# The index of this are the IDs of the test entries, while neigh_hadmid maps to the ID of the neighbour\n",
    "neigh_hadm_id = [dfd_cb_X.iloc[idx[0]].name for idx in nidxs]\n",
    "df_neighs = pd.DataFrame({'neigh_hadmid': neigh_hadm_id}, index=dfd_test_X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed summaries\n",
    "# This is required for CoT\n",
    "\n",
    "summaries_fpath = mimicpath / 'summaries'\n",
    "sum_model = 'llama3'\n",
    "summary_id = f'summary_S{samp_size}{'_balanced' if balanced_data else ''}_{sum_model}_mc{max_chars}'\n",
    "df_summaries = pd.read_csv(f'{summaries_fpath}/{summary_id}.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [BASE MODEL]: llama3\n",
      ">> Processing row 200 out of 200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sets ollama instance and run\n",
    "\n",
    "# First we load the system prompt configs from disk.\n",
    "# These will be used to build the right system prompt for each experiment\n",
    "with open(sysprompt_in_fpath, 'r') as ifile:\n",
    "    sprompt_data_in = json.load(ifile)\n",
    "\n",
    "with open(sysprompt_out_fpath, 'r') as ifile:\n",
    "    sprompt_data_out = json.load(ifile)\n",
    "\n",
    "# Getting related prompts for the specified input and output mode\n",
    "sprompt_in = sprompt_data_in[i_type_id]['prompt']\n",
    "sprompt_out = sprompt_data_out[o_type_id]['prompt']\n",
    "o_type_format = sprompt_data_out[o_type_id]['format']\n",
    "# Builds full system prompt\n",
    "sprompt = sprompt_in + \" \" + sprompt_out\n",
    "\n",
    "instance = 'http://localhost:11434/api/generate'\n",
    "auth_cookie = ''\n",
    "\n",
    "res_fpath = Path(f'{pjpath}/exps/results/llms/cot1nn')\n",
    "res_fpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "for base_model in base_models:\n",
    "    print(f'> [BASE MODEL]: {base_model}')\n",
    "    responses = {}\n",
    "    i=1\n",
    "    for index, row in df_test.iterrows():\n",
    "        print(f'>> Processing row {i} out of {len(df_test)}', end='\\r')\n",
    "\n",
    "        # Get summary text from entry\n",
    "        text = df_summaries.loc[index].iloc[0]\n",
    "\n",
    "        # Truncate middle if resulting text is longer than max_chars\n",
    "        if len(text) > max_chars:\n",
    "            print(f'(i) Text exceeds the max char limit ({len(text)}) in entry {index}. Middle-truncating to {max_chars}...')\n",
    "            text = text[:(max_chars//2)] + text[-(max_chars//2):]\n",
    "            print(f'... Result truncate: {len(text)}')\n",
    "\n",
    "        # Get neighour test from entry\n",
    "        neigh_hadm_id = df_neighs.loc[index]\n",
    "        neigh_text = df_summaries.loc[neigh_hadm_id]['SUMMARY'].iloc[0]\n",
    "        neigh_dies = df.loc[index]['DIES']\n",
    "\n",
    "        # Truncate middle if resulting text is longer than max_chars\n",
    "        if len(neigh_text) > max_chars:\n",
    "            print(f'(i) Neighbour text exceeds the max char limit ({len(neigh_text)}) in entry {index}. Middle-truncating to {max_chars}...')\n",
    "            neigh_text = neigh_text[:(max_chars//2)] + neigh_text[-(max_chars//2):]\n",
    "            print(f'... Result truncate: {len(neigh_text)}')\n",
    "\n",
    "        formatted_input = json.dumps({'REPORT': text})\n",
    "        formatted_input_neigh = json.dumps({'REPORT': neigh_text})\n",
    "        formatted_output_neigh = json.dumps({'DIES': neigh_dies})\n",
    "\n",
    "        # Builds full CoT prompt with example\n",
    "        cot1nn_prompt = \"\\nBelow is an example of the medical text report from which you will have to decide if the patient will die within 30 days of their medical discharge:\\n\"\n",
    "        cot1nn_prompt += formatted_input_neigh\n",
    "        cot1nn_prompt += \"\\nAnd here's its solution:\\n\"\n",
    "        cot1nn_prompt += formatted_output_neigh\n",
    "        cot1nn_prompt += \"\\nThe previous example is from a medical case that was marked as similar by another expert system. You must decide if the exemplar case is similar enough to another case you will be provided below, and if so, predict the mortality of the new case from its report and the known mortality from the similar case. If the cases are not similar enough, ignore the mortality of the example and try to predict the mortality of the case just from its text report.\\n\"\n",
    "        cot1nn_prompt += formatted_input\n",
    "\n",
    "        data = {'model': base_model,  # Explicit model to use\n",
    "            'options': {\n",
    "                'num_ctx': n_ctx * 1024,\n",
    "                'temperature': temp,\n",
    "                'seed': SEED,\n",
    "                'top_k': top_k,\n",
    "                'top_p': top_p\n",
    "                },\n",
    "            'keep-alive': 0,\n",
    "            'system': sprompt,\n",
    "            'prompt': cot1nn_prompt,\n",
    "            'stream': False,  # Wait and return all the result at once\n",
    "            'format': o_type_format\n",
    "        }\n",
    "\n",
    "        # Prepares query\n",
    "        data = json.dumps(data)\n",
    "        cookies = {\n",
    "            '_oauth2_proxy': auth_cookie}\n",
    "        headers = {\n",
    "            'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        }\n",
    "        cot1nn_response = requests.post(instance, cookies=cookies, headers=headers, data=data)\n",
    "        cot1nn_response_json = json.loads(cot1nn_response.text)['response']\n",
    "        responses[index] = json.loads(cot1nn_response_json) # Keeps the dictionary version of the json response\n",
    "        i+=1\n",
    "\n",
    "    # Export results\n",
    "    df_responses = pd.DataFrame(responses).T\n",
    "    test_id = f'{base_model}_{i_type_id}_{o_type_id}_{n_ctx}k_t{str(temp).replace('.', '')}'\n",
    "    df_responses.to_csv(res_fpath / f'{test_id}.csv')\n",
    "    print(f'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
